{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe3dbfb",
   "metadata": {},
   "source": [
    "# FORDATIS - Repositorium für Forschungsdaten der FhG\n",
    "\n",
    "<table table border=\"1\" align=\"left\">\n",
    " <tbody>\n",
    "    <tr>\n",
    "      <td>Autor: </td>\n",
    "      <td style=\"text-align: left\">Antje Schroeder (antje.schroeder@zv.fraunhofer.de)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Stand: </td>\n",
    "      <td style=\"text-align: left\">12/05/2023</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Zustand: </td>\n",
    "      <td style=\"text-align: left\">lauffähig, fertig</td>\n",
    "    </tr>\n",
    " </tbody>\n",
    "</table>\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "Dieses Skript fragt alle items aus FORDATIS ab. Items sind die Datensätze in FORDATIS. Es werden eine Ausgabedateie erzeugt, die nur die UUIDs (unique identifier) der Datensätze enthält. Diese Datei wird als Eingabedatei von weiteren Skritpen verarbeitet. Die zwei Datei enthält ein paar rudimentäre Metadaten zu jedem Datensatz. <br>\n",
    "\n",
    "* Eingabedatei: keine</br>\n",
    "* Ausgabedatei: fordatis_item_uuids.csv</br>\n",
    "* Ausgabedatei: fordatis_item_metadata.csv</br>\n",
    "* Datenverzeichnis: ../data</br>\n",
    "* FORDATIS BaseURL für Items: https://fordatis.fraunhofer.de/rest/items\n",
    "\n",
    "Dieses Skript benutzt die DSpace 6 Restfull-API:\n",
    "* https://fordatis.fraunhofer.de/apidocu.jsp\n",
    "* https://wiki.lyrasis.org/display/DSDOC6x/REST+API\n",
    "\n",
    "Informationen zur Abfrage über die FORDATIS-API: es werden i. d. R. 100 Datensätze zurückgeliefert (limit = 100). Da derzeit (05/12/2023) 110 Datensätze in FORDATIS abgelegt sind, muss einmal auf die zweite \"Seite\" iteriert werden, um die Datensätze 100-110 abzuholen. Sollten mehr als 199 Datensätze angelegt sein, ist es erforderlich, die letzten Code-Block anzupassen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92aed4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3168bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define environment \n",
    "\n",
    "output_dir = \"./data/\"\n",
    "output_uuids = output_dir + \"fordatis_item_uuids.csv\"\n",
    "output_metadata = output_dir + \"fordatis_item_metadata.csv\"\n",
    "\n",
    "base_url = \"https://fordatis.fraunhofer.de/rest/\"\n",
    "items = \"items?\"\n",
    "\n",
    "offset = 0\n",
    "limit = 100\n",
    "\n",
    "# Define column header for metadata output file\n",
    "fields = ['uuid', 'handle', 'name', 'date last modified']\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d126af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open output files\n",
    "\n",
    "with open(output_uuids, 'w', newline='', encoding=\"utf-8\") as f: # prepare output file \n",
    "    write = csv.writer(f)\n",
    "    \n",
    "with open(output_metadata, 'w', newline='', encoding=\"utf-8\") as f: # prepare output file \n",
    "    write = csv.writer(f)\n",
    "    write.writerow(fields) # write header to outputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "850cad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fordatis.fraunhofer.de/rest/items?offset=0&limit=100\n"
     ]
    }
   ],
   "source": [
    "# Construct request url\n",
    "get_item_urls = base_url + items + \"offset=\" + str(offset) + \"&limit=\" + str(limit)\n",
    "# get_item_urls = base_url + items\n",
    "print(get_item_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52709183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and create a pandas dataframe\n",
    "dataset = urllib.request.urlopen(get_item_urls).read()\n",
    "dataset = json.loads(dataset)\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ddc73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Get no of records to iter\n",
    "no_of_records = len(df)\n",
    "print(no_of_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7915f25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of records is:  100 Caution: We do have to iter through a next page. Please change code!\n"
     ]
    }
   ],
   "source": [
    "# Fetch data from data frame \n",
    "\n",
    "for i in range(no_of_records):\n",
    "    uuid = dataset[i][\"uuid\"]\n",
    "    name = dataset[i][\"name\"]\n",
    "    handle = dataset[i][\"handle\"]\n",
    "    link = dataset[i][\"link\"]\n",
    "    last_modified = dataset[i][\"lastModified\"]\n",
    "    mylist = [[uuid, handle, name, last_modified]]\n",
    "    uuid_list = [[uuid]]\n",
    "    \n",
    "    with open(output_metadata, 'a', newline='', encoding=\"utf-8\") as f:\n",
    "                write = csv.writer(f)\n",
    "                write.writerows(mylist)\n",
    "                \n",
    "    with open(output_uuids, 'a', newline='', encoding=\"utf-8\") as f:\n",
    "                write = csv.writer(f)\n",
    "                write.writerows(uuid_list)\n",
    "\n",
    "# Print out some information about records found\n",
    "if no_of_records < 100:\n",
    "    print(\"No of records is: \", no_of_records, \"which is lower than 100. We do not have to iter through a next page.\")\n",
    "else:\n",
    "    print(\"No of records is: \", no_of_records, \"Caution: We do have to iter through a next page. Please change code!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aca69e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of records is:  10 which is lower than 100. We do not have to iter through a next page.\n"
     ]
    }
   ],
   "source": [
    "# Iter through next page\n",
    "offset = 100\n",
    "get_item_urls = base_url + items + \"offset=\" + str(offset) + \"&limit=\" + str(limit)\n",
    "\n",
    "# Read data and create a pandas dataframe\n",
    "dataset = urllib.request.urlopen(get_item_urls).read()\n",
    "dataset = json.loads(dataset)\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Get no of records to iter\n",
    "no_of_records = len(df)\n",
    "\n",
    "if no_of_records < 100:\n",
    "    print(\"No of records is: \", no_of_records, \"which is lower than 100. We do not have to iter through a next page.\")\n",
    "else:\n",
    "    print(\"No of records is: \", no_of_records, \"Caution: We do have to iter through a next page. Please change code!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91882ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all things done.\n"
     ]
    }
   ],
   "source": [
    "# 1st Iteration for records above 100 up to 199. If 200 or more records are available please adjust offset parameter.\n",
    "# Fetch data from data frame \n",
    "\n",
    "for i in range(no_of_records):\n",
    "    uuid = dataset[i][\"uuid\"]\n",
    "    name = dataset[i][\"name\"]\n",
    "    handle = dataset[i][\"handle\"]\n",
    "    link = dataset[i][\"link\"]\n",
    "    last_modified = dataset[i][\"lastModified\"]\n",
    "    mylist = [[uuid, handle, name, last_modified]]\n",
    "    uuid_list = [[uuid]]\n",
    "    \n",
    "    with open(output_metadata, 'a', newline='', encoding=\"utf-8\") as f:\n",
    "                write = csv.writer(f)\n",
    "                write.writerows(mylist)\n",
    "                \n",
    "    with open(output_uuids, 'a', newline='', encoding=\"utf-8\") as f:\n",
    "                write = csv.writer(f)\n",
    "                write.writerows(uuid_list)\n",
    "                \n",
    "print(\"all things done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
